{
  "schemaVersion": 1,
  "projectName": "Piano Sheet Generator",
  "projectSummary": "A web app that isolates piano lines from songs using fal.ai SAM Audio, transcribes them to MIDI, and generates readable piano sheet music with export to PDF, MusicXML, and MIDI",
  "targetUsers": "Music learners wanting practice sheets, arrangers/transcribers needing editable exports, content creators needing quick notation for demos",
  "coreValue": "Turn piano lines from any song into clean, readable sheet music with minimal user effort",
  "mvpScope": "Upload audio, isolate piano via SAM Audio, transcribe to MIDI via Basic Pitch, generate sheet music via MuseScore, preview in-app with OpenSheetMusicDisplay, export as PDF/MusicXML/MIDI with readability controls",
  "createdAt": "2026-01-16T00:00:00.000Z",
  "stack": {
    "platform": "web",
    "frontend": "next.js",
    "backend": "node.js with python worker",
    "database": "sqlite",
    "auth": "none (anonymous)",
    "hosting": "local development"
  },
  "dependencies": {
    "packages": [
      {
        "name": "next",
        "reason": "React framework with file-based routing, API routes, and SSR support"
      },
      {
        "name": "react",
        "reason": "UI library for building the interactive frontend"
      },
      {
        "name": "typescript",
        "reason": "Type safety across the codebase"
      },
      {
        "name": "@fal-ai/client",
        "reason": "Official fal.ai client for SAM Audio API calls (replaces deprecated @fal-ai/serverless-client)"
      },
      {
        "name": "opensheetmusicdisplay",
        "reason": "Render MusicXML as interactive SVG in the browser, supports zoom and responsive layout"
      },
      {
        "name": "better-sqlite3",
        "reason": "Synchronous SQLite driver for Node.js, simpler than async alternatives for local dev"
      },
      {
        "name": "drizzle-orm",
        "reason": "Lightweight TypeScript ORM with SQLite support, type-safe queries"
      },
      {
        "name": "zod",
        "reason": "Schema validation for API inputs and job settings"
      },
      {
        "name": "uuid",
        "reason": "Generate unique job IDs"
      },
      {
        "name": "multer",
        "reason": "Multipart file upload handling for audio files"
      },
      {
        "name": "lucide-react",
        "reason": "Icon library matching the Swiss design system"
      },
      {
        "name": "tailwindcss",
        "reason": "Utility-first CSS framework for implementing the Swiss design system"
      },
      {
        "name": "@tailwindcss/typography",
        "reason": "Typography plugin for consistent text styling"
      }
    ],
    "services": [
      {
        "name": "fal.ai SAM Audio",
        "usage": "Piano isolation via text-prompted audio source separation",
        "envVars": ["FAL_KEY"],
        "notes": "Model: fal-ai/sam-audio/separate. Prompt: 'piano playing'. Cost: $0.05 per 30 seconds of output. Min 5 seconds audio. Returns target (piano) and residual (everything else) URLs."
      }
    ],
    "apis": [
      {
        "name": "fal.ai SAM Audio API",
        "usage": "Audio source separation to isolate piano from mixed tracks",
        "envVars": ["FAL_KEY"],
        "testMode": "Use fal.ai free tier credits for development",
        "docsUrl": "https://fal.ai/models/fal-ai/sam-audio/separate",
        "notes": "Rate limit: 10 concurrent tasks. Max concurrency: 5. Timeout: 3600s. Supported formats: mp3, wav, ogg, flac."
      }
    ]
  },
  "pythonDependencies": {
    "packages": [
      {
        "name": "basic-pitch",
        "reason": "Spotify's audio-to-MIDI transcription library. Fully local, ~17K params, faster than real-time, outputs pretty_midi objects."
      },
      {
        "name": "pretty_midi",
        "reason": "MIDI file manipulation, installed as basic-pitch dependency"
      },
      {
        "name": "flask",
        "reason": "Lightweight HTTP server for the Python worker to receive transcription requests"
      },
      {
        "name": "music21",
        "reason": "Music analysis and MIDI cleanup (quantization, voice separation, hand splitting)"
      }
    ],
    "systemDependencies": [
      {
        "name": "MuseScore 4",
        "reason": "CLI (mscore) for MIDI to MusicXML/PDF conversion",
        "installNotes": "macOS: brew install --cask musescore. Path: /Applications/MuseScore 4.app/Contents/MacOS/mscore. Headless mode requires QT_QPA_PLATFORM=offscreen environment variable."
      }
    ]
  },
  "testingPrerequisites": {
    "envVars": [
      {
        "name": "FAL_KEY",
        "description": "fal.ai API key for SAM Audio",
        "required": true
      }
    ],
    "seedData": [
      {
        "description": "Test audio files",
        "details": "Short (30s) mp3/wav files with clear piano parts for testing the pipeline"
      }
    ],
    "fixtures": [
      {
        "description": "Sample MIDI file",
        "details": "Pre-transcribed MIDI for testing notation generation without API calls"
      },
      {
        "description": "Sample MusicXML file",
        "details": "Pre-generated MusicXML for testing OSMD preview without full pipeline"
      }
    ]
  },
  "design": {
    "references": [
      {
        "name": "Swiss International Style",
        "url": null,
        "inspiration": "1950s Swiss typography - objective communication, mathematical precision, logical structure, grid as law"
      }
    ],
    "vibe": "intellectual, architectural, brutally precise, timeless",
    "colorMode": "light",
    "colors": {
      "background": "#FFFFFF",
      "foreground": "#000000",
      "muted": "#F2F2F2",
      "accent": "#FF3000 (Swiss Red)",
      "style": "strict monochrome with single accent color"
    },
    "typography": "Inter font family. Black (900) and Bold (700) for headings, Regular (400) for body. UPPERCASE for headings and labels. Massive responsive scale (text-7xl to text-9xl for headlines).",
    "style": {
      "borders": "thick visible borders (border-2 or border-4), pure black",
      "corners": "strictly rectangular (rounded-none)",
      "spacing": "generous whitespace, high density in data clusters",
      "density": "active negative space as structural element",
      "shadows": "none - flat design",
      "textures": "subtle CSS patterns (24px grid, 16px dots, diagonals, noise) for depth"
    },
    "constraints": [
      "No gradients",
      "No rounded corners",
      "No shadows or 3D effects",
      "Red used only functionally (CTAs, emphasis, warnings)",
      "Asymmetric layouts preferred over centered"
    ],
    "notes": "The grid is visible through borders and patterns. Typography is the primary structural element. Interactions are instant and mechanical (duration-200, no elastic animations). Color inversion on hover states."
  },
  "features": [
    {
      "id": "feat-upload",
      "name": "Audio Upload",
      "summary": "Upload audio files for processing with validation and progress feedback",
      "userFlows": [
        "User drags audio file onto upload zone → file validates (format, size) → upload progress shows → file stored locally → job created in UPLOADED state",
        "User clicks upload zone → file picker opens → selects file → same flow as drag",
        "User uploads invalid format → inline error with supported formats list",
        "User uploads file → sees file name, duration, and format confirmation"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "id (uuid), status, progress (0-100), input_file_path, input_file_name, input_duration_seconds, isolated_piano_path, midi_path, musicxml_path, pdf_path, settings_json, error_code, error_message, created_at, updated_at",
          "notes": "Single table tracks entire job lifecycle"
        }
      ],
      "uiNotes": [
        "Large drag-drop zone with dashed black border (4px)",
        "Upload icon (Lucide) centered in zone",
        "Uppercase label: 'DROP AUDIO FILE OR CLICK TO UPLOAD'",
        "Supported formats listed below: MP3, WAV, FLAC, OGG",
        "Progress bar appears during upload (black fill on white track)",
        "File info card after upload: name, duration, format badge"
      ],
      "edgeCases": [
        "Invalid format → 'UNSUPPORTED FORMAT. USE MP3, WAV, FLAC, OR OGG.'",
        "File too large (>500MB) → 'FILE TOO LARGE. MAXIMUM 500MB.'",
        "Upload network error → 'UPLOAD FAILED. TRY AGAIN.' with retry button",
        "Empty file → 'FILE IS EMPTY.'",
        "Corrupted audio → detected during isolation phase, show specific error"
      ],
      "researchFindings": [
        "fal.ai accepts mp3, wav, ogg, flac formats",
        "Minimum 5 seconds audio required by SAM Audio",
        "No hard duration limit but longer files increase processing time"
      ]
    },
    {
      "id": "feat-isolation",
      "name": "Piano Isolation",
      "summary": "Extract piano audio from uploaded file using fal.ai SAM Audio API",
      "userFlows": [
        "Job moves to ISOLATING state → progress updates shown → SAM Audio API called with 'piano playing' prompt → target (piano) and residual URLs returned → piano audio downloaded and stored locally → job moves to TRANSCRIBING state",
        "Isolation fails → job moves to FAILED state with error details → user sees error and can retry"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "status='ISOLATING', isolated_piano_path (local path after download)",
          "notes": "Store downloaded piano audio locally for transcription step"
        }
      ],
      "uiNotes": [
        "Progress page with stepper UI showing current phase",
        "Steps: 01. UPLOAD → 02. ISOLATE → 03. TRANSCRIBE → 04. NOTATE → 05. DONE",
        "Current step highlighted with Swiss Red",
        "Progress percentage shown for current step",
        "Subtle animation on active step (not bouncy - mechanical)"
      ],
      "edgeCases": [
        "Weak piano signal → SAM Audio may return mostly silence in target. Proceed anyway - quality visible in preview.",
        "API rate limit → retry with exponential backoff (3 attempts)",
        "API timeout → 'ISOLATION TIMED OUT. TRY A SHORTER FILE.'",
        "Invalid audio (detected by fal.ai) → 'AUDIO FILE COULD NOT BE PROCESSED.'",
        "No piano detected → still returns result, user can hear isolated audio to verify"
      ],
      "researchFindings": [
        "fal.ai SAM Audio model: fal-ai/sam-audio/separate",
        "Prompt for piano: 'piano playing'",
        "Returns target (isolated piano) and residual (everything else) as URLs",
        "Cost: $0.05 per 30 seconds of output audio",
        "Rate limit: 10 concurrent tasks, 5 max concurrency per model",
        "Supported acceleration modes: fast, balanced, quality"
      ]
    },
    {
      "id": "feat-transcription",
      "name": "Audio to MIDI Transcription",
      "summary": "Convert isolated piano audio to MIDI using Spotify Basic Pitch",
      "userFlows": [
        "Job in TRANSCRIBING state → Python worker receives request → Basic Pitch processes audio → MIDI data returned → saved to local file → job moves to NOTATING state",
        "Transcription fails → job moves to FAILED with error → user sees error and can retry"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "status='TRANSCRIBING', midi_path (local path to generated MIDI)",
          "notes": "MIDI file stored for notation step and user download"
        }
      ],
      "uiNotes": [
        "Same stepper UI, now on step 03. TRANSCRIBE",
        "Progress updates as transcription proceeds"
      ],
      "edgeCases": [
        "Empty/silent audio → produces empty or near-empty MIDI. Show warning: 'NO NOTES DETECTED. CHECK ISOLATED AUDIO.'",
        "Very long audio → may be slow. No hard limit but show progress.",
        "Python worker unavailable → 'TRANSCRIPTION SERVICE UNAVAILABLE. TRY AGAIN.'",
        "Out of memory → 'TRANSCRIPTION FAILED. TRY A SHORTER FILE.'"
      ],
      "researchFindings": [
        "Basic Pitch: pip install basic-pitch",
        "Fully local inference, no API calls",
        "~17,000 parameters, <20MB peak memory",
        "Faster than real-time on modern hardware",
        "Supports mp3, wav, flac, ogg, m4a input",
        "Returns pretty_midi object with pitch bend detection",
        "Best with single instruments - good fit since we pre-isolate piano"
      ]
    },
    {
      "id": "feat-notation",
      "name": "Sheet Music Generation",
      "summary": "Convert MIDI to readable sheet music (MusicXML and PDF) using MuseScore CLI with readability processing",
      "userFlows": [
        "Job in NOTATING state → MIDI cleanup applied (quantization, hand splitting) → MuseScore CLI converts to MusicXML → MuseScore CLI converts to PDF → files stored locally → job moves to DONE state",
        "User adjusts readability settings → clicks regenerate → MIDI reprocessed with new settings → new MusicXML/PDF generated"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "status='NOTATING', musicxml_path, pdf_path, settings_json (readability settings)",
          "notes": "settings_json stores quantization grid, simplification level, hand split point, etc."
        }
      ],
      "uiNotes": [
        "Same stepper UI, now on step 04. NOTATE",
        "Progress updates during conversion"
      ],
      "edgeCases": [
        "MuseScore not installed → 'MUSESCORE NOT FOUND. INSTALL MUSESCORE 4.'",
        "Conversion fails → 'NOTATION GENERATION FAILED.' with specific error",
        "Empty MIDI → produces empty sheet. Show warning.",
        "Complex passages → may produce dense notation. Readability controls help."
      ],
      "researchFindings": [
        "MuseScore 4 CLI: /Applications/MuseScore 4.app/Contents/MacOS/mscore on macOS",
        "Headless mode: QT_QPA_PLATFORM=offscreen mscore -o output.pdf input.mid",
        "Quantization via -M midi_import_options.xml (poorly documented XML format)",
        "MIDI inherently lacks notation info (enharmonics, articulation) - quality depends on cleanup",
        "MuseScore 4 removed MIDI import panel - less interactive control than v3"
      ]
    },
    {
      "id": "feat-preview",
      "name": "Sheet Music Preview",
      "summary": "Display generated sheet music in-app using OpenSheetMusicDisplay with zoom and responsive layout",
      "userFlows": [
        "Job completes → results page loads → OSMD renders MusicXML as SVG → user can zoom in/out → user can scroll through pages",
        "User plays isolated audio while viewing sheet → audio playback controls available"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "musicxml_path (read for OSMD rendering)",
          "notes": "MusicXML loaded from local path and rendered client-side"
        }
      ],
      "uiNotes": [
        "Full-width sheet display with black border (4px)",
        "Zoom controls: + / - buttons with current zoom percentage",
        "Sheet renders in scrollable container",
        "Audio player for isolated piano: play/pause, seek bar, time display",
        "Side-by-side layout on desktop: audio player left, sheet right",
        "Stacked layout on mobile: audio player top, sheet below"
      ],
      "edgeCases": [
        "Large score (many pages) → may be slow. OSMD has performance optimizations for 80+ measures.",
        "MusicXML load error → 'COULD NOT LOAD SHEET MUSIC. TRY REGENERATING.'",
        "Browser doesn't support SVG → extremely rare, show fallback message"
      ],
      "researchFindings": [
        "opensheetmusicdisplay v1.9.3 on npm",
        "Requires dynamic import with ssr: false in Next.js",
        "load() accepts URL, XML Document, or raw string",
        "setZoom(value) for programmatic zoom",
        "autoResize option for responsive behavior",
        "Cursor system available (enableOrDisableCursors) for playback sync",
        "30-60% faster in v1.5 with batch processing and WebGL"
      ]
    },
    {
      "id": "feat-readability",
      "name": "Readability Controls",
      "summary": "User-adjustable settings to improve sheet music readability through quantization and simplification",
      "userFlows": [
        "User on results page → expands readability panel → adjusts settings (quantization, simplification, hand split) → clicks 'REGENERATE' → new sheet generated with settings → preview updates",
        "User resets to defaults → regenerates with default settings"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "settings_json containing: quantization_grid, simplification_level, min_note_duration_ms, velocity_threshold, hand_split_note, tempo_bpm",
          "notes": "Settings persisted per job, used during NOTATING phase"
        }
      ],
      "uiNotes": [
        "Collapsible panel: 'READABILITY SETTINGS'",
        "Quantization grid: dropdown (1/8, 1/16, 1/32)",
        "Simplification level: radio buttons (SIMPLE / MEDIUM / EXACT)",
        "Hand split point: number input (MIDI note, default 60 = middle C)",
        "Min note duration: slider (50-500ms)",
        "Velocity threshold: slider (0-127)",
        "Tempo: number input (BPM) or 'AUTO DETECT'",
        "'REGENERATE' button (Swiss Red background, white text)",
        "'RESET TO DEFAULTS' link"
      ],
      "edgeCases": [
        "Invalid settings → validation error shown inline",
        "Regeneration fails → show error, keep previous version available",
        "Settings don't improve output → user education: some recordings are inherently difficult"
      ],
      "researchFindings": [
        "Quantization grid affects note alignment to beat divisions",
        "Hand splitting at note number divides notes between treble and bass clef",
        "Velocity threshold filters out quiet notes (ghost notes, noise)",
        "music21 Python library can handle MIDI cleanup programmatically"
      ]
    },
    {
      "id": "feat-export",
      "name": "Export Functionality",
      "summary": "Download generated files in PDF, MusicXML, and MIDI formats",
      "userFlows": [
        "User on results page → clicks 'DOWNLOAD PDF' → PDF file downloads",
        "User clicks 'DOWNLOAD MUSICXML' → MusicXML file downloads",
        "User clicks 'DOWNLOAD MIDI' → MIDI file downloads",
        "User clicks 'DOWNLOAD ISOLATED AUDIO' → isolated piano WAV downloads"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "pdf_path, musicxml_path, midi_path, isolated_piano_path",
          "notes": "All files stored locally, served via API endpoints"
        }
      ],
      "uiNotes": [
        "Export section with clear button row",
        "Each button: icon + format name, black background, white text",
        "Hover: invert to Swiss Red",
        "Buttons: PDF | MUSICXML | MIDI | AUDIO (isolated piano)",
        "File names include original audio name: '{original}_piano.pdf'"
      ],
      "edgeCases": [
        "File not found → 'FILE NOT AVAILABLE. TRY REGENERATING.'",
        "Download interrupted → browser handles retry"
      ],
      "researchFindings": []
    },
    {
      "id": "feat-job-history",
      "name": "Job History",
      "summary": "View and access recent processing jobs",
      "userFlows": [
        "User visits home page → sees list of recent jobs (stored in browser localStorage + SQLite)",
        "User clicks a job → navigates to that job's results/progress page",
        "User deletes a job → job removed from list and files cleaned up"
      ],
      "dataRequirements": [
        {
          "table": "jobs",
          "fields": "All job data queryable for history list",
          "notes": "Jobs persist in SQLite. No user accounts - jobs are accessible by anyone with the job ID."
        }
      ],
      "uiNotes": [
        "Home page shows recent jobs in a table/list",
        "Columns: FILE NAME | STATUS | DATE | ACTIONS",
        "Status badges: PROCESSING (black), DONE (Swiss Red), FAILED (black outline)",
        "Actions: VIEW | DELETE",
        "Empty state: 'NO JOBS YET. UPLOAD AN AUDIO FILE TO GET STARTED.'"
      ],
      "edgeCases": [
        "Job files deleted from disk → show 'FILES UNAVAILABLE' status",
        "Very old jobs → no auto-cleanup in MVP, manual deletion"
      ],
      "researchFindings": []
    }
  ]
}
